{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import selenium \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://www.myscheme.gov.in/schemes/fapsubnc1t12cw-hlwb'\n",
    "driver = webdriver.Chrome()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Assistance for Purchasing School Uniforms, Books and Notebooks from Class 1st to 12th for Children of Workers- Haryana Labour Welfare Board\n"
     ]
    }
   ],
   "source": [
    "driver.get(website)\n",
    "\n",
    "title1 = driver.find_element(By.XPATH,'//*[@id=\"scrollDiv\"]/div[1]/div[4]/div[1]/div/div[1]/div[1]/h1')\n",
    "\n",
    "# Extract and print the title attribute\n",
    "title = title1.get_attribute(\"title\")\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags1 = driver.find_elements(By.CLASS_NAME,'text-gray-800 bg-gray-100 dark:bg-gray-800 dark:text-gray-100 dark:hover:bg-gray-700 rounded  py-2 px-3.5 text-sm   inline-block font-medium leading-none  text-left md:text-center rounded hover:shadow-md mr-2 mt-1 cursor-pointer ')\n",
    "tags = []\n",
    "for item in driver.find_elements(By.CLASS_NAME,'text-gray-800'):\n",
    "    tags.append(item.get_attribute(\"title\"))\n",
    "\n",
    "# print(tags1)\n",
    "# tags = []\n",
    "# for tag in tags1:\n",
    "#     tags.append(tag.get_attribute(\"title\"))\n",
    "# print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scheme “Financial Assistance for Purchasing School Uniforms, Books and Notebooks from Class 1st to 12th for Children of Workers” is implemented by the Haryana Labour Welfare Board (HLWB), Labour Department, Government of Haryana. Under this scheme, one-time financial assistance is provided to the children (2 boys & 3 girls) of workers employed in industrial and commercial establishments of the state of Haryana at the time of admission to continue their studies. The Board provides assistance for the sons and daughters of registered workers for the purchase of school uniforms, books, stationery, and other educational materials, enabling them to continue their studies from 1st to 12th standard.\n"
     ]
    }
   ],
   "source": [
    "span_element = driver.find_element(By.XPATH, \"//div[@id='details']//span[@data-slate-string='true']\")\n",
    "\n",
    "# Extract the text content\n",
    "details = span_element.text\n",
    "\n",
    "# Print the extracted text\n",
    "print(details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_section(driver, section_id):\n",
    "    \"\"\"Extracts text content from a section, handling missing tables gracefully.\n",
    "\n",
    "    Args:\n",
    "        driver: The Selenium WebDriver object.\n",
    "        section_id: The ID of the section to extract from.\n",
    "\n",
    "    Returns:\n",
    "        A list containing extracted text:\n",
    "            - Each element is either a string (for text outside tables) \n",
    "              or a list of strings (for table rows).\n",
    "    \"\"\"\n",
    "\n",
    "    extracted_data = []\n",
    "    section_div = driver.find_element(By.ID, section_id)\n",
    "\n",
    "    # 1. Extract text outside tables \n",
    "    text_elements = section_div.find_elements(By.XPATH, \".//span[@data-slate-string='true'] | .//p\")\n",
    "    for element in text_elements:\n",
    "        extracted_data.append(element.text)\n",
    "\n",
    "    # 2. Extract table data (with error handling)\n",
    "    try:\n",
    "        tables = section_div.find_elements(By.TAG_NAME, 'table')\n",
    "        for table in tables:\n",
    "            rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "            for row in rows:\n",
    "                cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "                row_data = [cell.text for cell in cells]\n",
    "                extracted_data.append(row_data)\n",
    "    except NoSuchElementException:\n",
    "        print(f\"No table found in section '{section_id}'. Skipping table extraction.\")\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "benefits_data = extract_text_from_section(driver, 'benefits')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligibility Section:\n",
      "The applicant should be employed in an industrial or commercial establishment in Haryana.\n",
      "The worker should be registered with the Haryana Labour Welfare Board.\n",
      "The monthly salary of the worker should not exceed ₹25,000/-.\n",
      "The service period of the workers is fixed for two years.\n",
      "The worker's children studying in Class I to Class XII are eligible for the scheme's benefits at the time of admission to continue their studies.\n",
      "The scheme benefits are available to three girls and two boys per worker.\n",
      "The name of the child/children should be mentioned on the Ration Card/ESI Card of the worker.\n",
      "Note 01:\n",
      " The last date for submission of applications in the respective sessions has been fixed as 31st December. Applications submitted after 31st December will not be considered.\n",
      "Note 02: \n",
      "The benefit of the scheme will be made available to the girls as well as boys of the worker.\n",
      "The applicant should be employed in an industrial or commercial establishment in Haryana.\n",
      "The worker should be registered with the Haryana Labour Welfare Board.\n",
      "The monthly salary of the worker should not exceed ₹25,000/-.\n",
      "The service period of the workers is fixed for two years.\n",
      "The worker's children studying in Class I to Class XII are eligible for the scheme's benefits at the time of admission to continue their studies.\n",
      "The scheme benefits are available to three girls and two boys per worker.\n",
      "The name of the child/children should be mentioned on the Ration Card/ESI Card of the worker.\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_section(driver, section_xpath): \n",
    "    \"\"\"Extracts text content from a section, handling tables and lists. \n",
    "\n",
    "    Args:\n",
    "        driver: The Selenium WebDriver object.\n",
    "        section_xpath: The XPath of the section to extract from.\n",
    "\n",
    "    Returns:\n",
    "        A list containing extracted text.\n",
    "    \"\"\"\n",
    "\n",
    "    extracted_data = []\n",
    "    section_div = driver.find_element(By.XPATH, section_xpath)\n",
    "\n",
    "    # 1. Extract text outside tables and lists\n",
    "    text_elements = section_div.find_elements(\n",
    "        By.XPATH, \".//span[@data-slate-string='true'] | .//p\"\n",
    "    )\n",
    "    for element in text_elements:\n",
    "        extracted_data.append(element.text)\n",
    "\n",
    "    # 2. Extract table data (with error handling)\n",
    "    try:\n",
    "        tables = section_div.find_elements(By.TAG_NAME, 'table')\n",
    "        for table in tables:\n",
    "            rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "            for row in rows:\n",
    "                cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "                row_data = [cell.text for cell in cells]\n",
    "                extracted_data.append(row_data)\n",
    "    except NoSuchElementException:\n",
    "        print(f\"No table found in section '{section_xpath}'. Skipping table extraction.\")\n",
    "\n",
    "    # 3. Extract list items (from <ol> or <ul>)\n",
    "    list_elements = section_div.find_elements(By.XPATH, \".//ol | .//ul\")\n",
    "    for list_element in list_elements:\n",
    "        list_items = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "        for item in list_items:\n",
    "            extracted_data.append(item.text)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "# Initialize WebDriver (example: Chrome)\n",
    "\n",
    "pathE = '/html/body/div/div/main/div[2]/div[1]/div/div/div[2]/div/div[4]'\n",
    "# Example usage:\n",
    "eligibility_data = extract_text_from_section(driver, pathE)\n",
    "\n",
    "# Print extracted data\n",
    "print(\"Eligibility Section:\")\n",
    "for item in eligibility_data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_application_process(driver):\n",
    "    \"\"\"Extracts application process details from the provided HTML structure.\n",
    "\n",
    "    Args:\n",
    "        driver: The Selenium WebDriver object.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing extracted details:\n",
    "            - 'application_mode': The application mode (e.g., 'Online').\n",
    "            - 'steps': A list of dictionaries, where each dictionary represents \n",
    "                      a step and contains the step title and description.\n",
    "    \"\"\"\n",
    "\n",
    "    section_xpath = '/html/body/div/div/main/div[2]/div[1]/div/div/div[2]/div/div[5]'\n",
    "    section_div = driver.find_element(By.XPATH, section_xpath)\n",
    "\n",
    "    # 1. Extract Application Mode \n",
    "    application_mode = section_div.find_element(\n",
    "        By.XPATH, \".//span[contains(@class, 'capitalize') and contains(text(), 'Online')]\"\n",
    "    ).text.strip() \n",
    "\n",
    "    # 2. Extract Steps \n",
    "    steps = []\n",
    "    step_elements = section_div.find_elements(By.XPATH, \".//div[contains(@class, 'mb-2')]/span[1]\")\n",
    "    description_elements = section_div.find_elements(By.XPATH, \".//div[contains(@class, 'mb-2')]/span[position() > 1]\") \n",
    "\n",
    "    for step_element, description_element in zip(step_elements, description_elements):\n",
    "        step_title = step_element.text.strip()\n",
    "        step_description = description_element.text.strip()\n",
    "        steps.append({'title': step_title, 'description': step_description})\n",
    "\n",
    "    return {'application_mode': application_mode, 'steps': steps}\n",
    "\n",
    "\n",
    "# Extract application process details\n",
    "application_process_data = extract_text_from_application_process(driver)\n",
    "\n",
    "# Print extracted data\n",
    "print(\"Application Mode:\", application_process_data['application_mode'])\n",
    "print(\"\\nSteps:\")\n",
    "for i, step in enumerate(application_process_data['steps']):\n",
    "    print(f\"{i+1}. {step['title']}: {step['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
